{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8de338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NGAsubRSN</th>\n",
       "      <th>DatabaseRegion</th>\n",
       "      <th>NGAsubEQID</th>\n",
       "      <th>NGAsubSSN</th>\n",
       "      <th>Earthquake_Name</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MODY</th>\n",
       "      <th>HRMN</th>\n",
       "      <th>Earthquake_Magnitude</th>\n",
       "      <th>Hypocenter_Latitude_deg</th>\n",
       "      <th>...</th>\n",
       "      <th>T8pt500S</th>\n",
       "      <th>T9pt000S</th>\n",
       "      <th>T9pt500S</th>\n",
       "      <th>T10pt000S</th>\n",
       "      <th>T11pt000S</th>\n",
       "      <th>T12pt000S</th>\n",
       "      <th>T13pt000S</th>\n",
       "      <th>T14pt000S</th>\n",
       "      <th>T15pt000S</th>\n",
       "      <th>T20pt000S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>Aleutian_Isl-Alaska</td>\n",
       "      <td>2014</td>\n",
       "      <td>623</td>\n",
       "      <td>2053</td>\n",
       "      <td>7.96</td>\n",
       "      <td>51.6928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000002</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000002</td>\n",
       "      <td>Aleutian_Isl-Alaska</td>\n",
       "      <td>2014</td>\n",
       "      <td>623</td>\n",
       "      <td>2053</td>\n",
       "      <td>7.96</td>\n",
       "      <td>51.6928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000003</td>\n",
       "      <td>Aleutian_Isl-Alaska</td>\n",
       "      <td>2014</td>\n",
       "      <td>623</td>\n",
       "      <td>2053</td>\n",
       "      <td>7.96</td>\n",
       "      <td>51.6928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000004</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000004</td>\n",
       "      <td>Aleutian_Isl-Alaska</td>\n",
       "      <td>2014</td>\n",
       "      <td>623</td>\n",
       "      <td>2053</td>\n",
       "      <td>7.96</td>\n",
       "      <td>51.6928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000005</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000005</td>\n",
       "      <td>Aleutian_Isl-Alaska</td>\n",
       "      <td>2014</td>\n",
       "      <td>623</td>\n",
       "      <td>2053</td>\n",
       "      <td>7.96</td>\n",
       "      <td>51.6928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NGAsubRSN DatabaseRegion  NGAsubEQID  NGAsubSSN      Earthquake_Name  YEAR  \\\n",
       "0    1000001         Alaska     1000001    1000001  Aleutian_Isl-Alaska  2014   \n",
       "1    1000002         Alaska     1000001    1000002  Aleutian_Isl-Alaska  2014   \n",
       "2    1000003         Alaska     1000001    1000003  Aleutian_Isl-Alaska  2014   \n",
       "3    1000004         Alaska     1000001    1000004  Aleutian_Isl-Alaska  2014   \n",
       "4    1000005         Alaska     1000001    1000005  Aleutian_Isl-Alaska  2014   \n",
       "\n",
       "   MODY  HRMN  Earthquake_Magnitude  Hypocenter_Latitude_deg  ...  T8pt500S  \\\n",
       "0   623  2053                  7.96                  51.6928  ...  0.000082   \n",
       "1   623  2053                  7.96                  51.6928  ...  0.000415   \n",
       "2   623  2053                  7.96                  51.6928  ...  0.000092   \n",
       "3   623  2053                  7.96                  51.6928  ...  0.000055   \n",
       "4   623  2053                  7.96                  51.6928  ...  0.000129   \n",
       "\n",
       "   T9pt000S  T9pt500S  T10pt000S  T11pt000S  T12pt000S  T13pt000S  T14pt000S  \\\n",
       "0  0.000095  0.000103   0.000125   0.000138   0.000109   0.000089   0.000064   \n",
       "1  0.000395  0.000405   0.000390   0.000336   0.000332   0.000263   0.000215   \n",
       "2  0.000083  0.000086   0.000082   0.000091   0.000078   0.000071   0.000066   \n",
       "3  0.000053  0.000051   0.000055   0.000059   0.000058   0.000042   0.000035   \n",
       "4  0.000116  0.000128   0.000122   0.000130   0.000119   0.000096   0.000135   \n",
       "\n",
       "   T15pt000S  T20pt000S  \n",
       "0   0.000053   0.000061  \n",
       "1   0.000187   0.000119  \n",
       "2   0.000060   0.000055  \n",
       "3   0.000038   0.000028  \n",
       "4   0.000162   0.000060  \n",
       "\n",
       "[5 rows x 227 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = r\"A:\\Seismic_data_analysis\\Seismic-Data-analysis\\Data\\NGAsub_MegaFlatfile_RotD50_050_R211022_public.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eac287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (54140, 6)\n",
      "Output shape: (54140, 113)\n"
     ]
    }
   ],
   "source": [
    "df_fil = df[\n",
    "    (df['Earthquake_Magnitude'] >= 4) & \n",
    "    (df['Rjb_km'] > 0) & \n",
    "    (df['Rjb_km'] <= 500) & \n",
    "    (df['Vs30_Selected_for_Analysis_m_s'] > 0) & \n",
    "    (df['Hypocenter_Depth_km'] > 0) &\n",
    "    (df[\"Fault_Type\"] >= 0)\n",
    "    \n",
    "].copy()\n",
    "\n",
    "# Inputs\n",
    "X = pd.DataFrame()\n",
    "X['M']         = df_fil['Earthquake_Magnitude']\n",
    "X['logVs']     = np.log10(df_fil['Vs30_Selected_for_Analysis_m_s'])\n",
    "X['logRrup']   = np.log10(df_fil['Rjb_km'])\n",
    "X['Hyp_depth'] = df_fil['Hypocenter_Depth_km']\n",
    "X[\"Rup\"] = df_fil[\"Rjb_km\"]\n",
    "X[\"Fault_Type\"] = df_fil[\"Fault_Type\"]\n",
    "# Outputs\n",
    "time_cols = [col for col in df_fil.columns if col.startswith('T') and col.endswith('S')]\n",
    "output_cols = time_cols + ['PGA_g', 'PGV_cm_sec']\n",
    "\n",
    "epsilon = 1e-8\n",
    "y = np.log10(df_fil[output_cols].clip(lower=epsilon))\n",
    "\n",
    "# Convert\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "\n",
    "print(\"Input shape:\", X.shape)\n",
    "print(\"Output shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf70b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanji\\AppData\\Local\\Temp\\ipykernel_8212\\2967107730.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X , dtype = torch.float32 , device = device )\n",
      "C:\\Users\\sanji\\AppData\\Local\\Temp\\ipykernel_8212\\2967107730.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y , dtype = torch.float32 , device = device )\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X = torch.tensor(X , dtype = torch.float32 , device = device )\n",
    "y = torch.tensor(y , dtype = torch.float32 , device = device )\n",
    "\n",
    "# test train split\n",
    "perm = torch.randperm(X.shape[0] , device=device)\n",
    "\n",
    "X , y = X[perm] , y[perm]\n",
    "\n",
    "split = int(0.8 * (X.shape[0]))\n",
    "\n",
    "X_train , X_test = X[ :split] , X[split : ]\n",
    "y_train , y_test = y[ :split] , y[split : ]\n",
    "\n",
    "# normalization \n",
    "X_mean = X_train.mean(dim=0)  \n",
    "X_std  = X_train.std(dim=0)\n",
    "\n",
    "X_train = (X_train - X_mean) / (X_std + 1e-8)  \n",
    "X_test  = (X_test  - X_mean) / (X_std + 1e-8) \n",
    "\n",
    "y_mean = y_train.mean(dim=0)  \n",
    "y_std  = y_train.std(dim=0)   \n",
    "\n",
    "y_train = (y_train - y_mean) / (y_std + 1e-8)\n",
    "y_test  = (y_test  - y_mean) / (y_std + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b610f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN for each feature\n",
    "def make_subnet(hidden=64, out_dim=32, ):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(1, hidden),       \n",
    "        nn.LayerNorm(hidden),       \n",
    "        nn.ReLU(),                  \n",
    "               \n",
    "        nn.Linear(hidden, hidden),\n",
    "        nn.LayerNorm(hidden),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(hidden, out_dim), \n",
    "        nn.LayerNorm(out_dim),\n",
    "    )\n",
    "\n",
    "# Additive model architeture \n",
    "class NAM(nn.Module):\n",
    "    def __init__(self, n_features=6, n_outputs=113, hidden=64, subnet_out=32, dropout=0.15):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.subnets = nn.ModuleList([\n",
    "            make_subnet(hidden, subnet_out)\n",
    "            for _ in range(n_features)\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.output_layer = nn.Linear(n_features * subnet_out, n_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 6)\n",
    "        outs = []\n",
    "        for j, net in enumerate(self.subnets):\n",
    "            xj = x[:, j].unsqueeze(1)  \n",
    "            outs.append(net(xj))        \n",
    "        concat = torch.cat(outs, dim=1)    \n",
    "        return self.output_layer(concat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb31000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NAM(\n",
    "    n_features=6,\n",
    "    n_outputs=113,\n",
    "    hidden=64,\n",
    "    subnet_out=32,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3, weight_decay=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=50, T_mult=2, eta_min=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_true, y_pred):\n",
    "    # y_true, y_pred: shape (N, 113)\n",
    "    ss_res = ((y_true - y_pred) ** 2).sum(dim=0)              \n",
    "    ss_tot = ((y_true - y_true.mean(dim=0)) ** 2).sum(dim=0)  \n",
    "    \n",
    "    r2_per_output = 1.0 - ss_res / (ss_tot + 1e-8)          \n",
    "    r2_per_output = r2_per_output.clamp(min=-1.0)           \n",
    "    \n",
    "    return r2_per_output.mean().item(), r2_per_output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3e5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 | loss 0.3341 | val R² 0.6459 | outputs with R²<0: 0\n",
      "Epoch   10 | loss 0.3256 | val R² 0.6575 | outputs with R²<0: 0\n",
      "Epoch   20 | loss 0.3203 | val R² 0.6573 | outputs with R²<0: 0\n",
      "Epoch   30 | loss 0.3176 | val R² 0.6611 | outputs with R²<0: 0\n",
      "Epoch   40 | loss 0.3155 | val R² 0.6621 | outputs with R²<0: 0\n",
      "Epoch   50 | loss 0.3144 | val R² 0.6629 | outputs with R²<0: 0\n",
      "Epoch   60 | loss 0.3210 | val R² 0.6591 | outputs with R²<0: 0\n",
      "Epoch   70 | loss 0.3225 | val R² 0.6598 | outputs with R²<0: 0\n",
      "Epoch   80 | loss 0.3204 | val R² 0.6569 | outputs with R²<0: 0\n",
      "Epoch   90 | loss 0.3231 | val R² 0.6611 | outputs with R²<0: 0\n",
      "Epoch  100 | loss 0.3205 | val R² 0.6608 | outputs with R²<0: 0\n",
      "Epoch  110 | loss 0.3143 | val R² 0.6635 | outputs with R²<0: 0\n",
      "Epoch  120 | loss 0.3132 | val R² 0.6642 | outputs with R²<0: 0\n",
      "Epoch  130 | loss 0.3137 | val R² 0.6661 | outputs with R²<0: 0\n",
      "Epoch  140 | loss 0.3108 | val R² 0.6665 | outputs with R²<0: 0\n",
      "Epoch  150 | loss 0.3099 | val R² 0.6667 | outputs with R²<0: 0\n",
      "Epoch  160 | loss 0.3239 | val R² 0.6599 | outputs with R²<0: 0\n",
      "Epoch  170 | loss 0.3201 | val R² 0.6611 | outputs with R²<0: 0\n",
      "Epoch  180 | loss 0.3193 | val R² 0.6586 | outputs with R²<0: 0\n",
      "Epoch  190 | loss 0.3156 | val R² 0.6624 | outputs with R²<0: 0\n",
      "Epoch  200 | loss 0.3149 | val R² 0.6614 | outputs with R²<0: 0\n",
      "Epoch  210 | loss 0.3179 | val R² 0.6641 | outputs with R²<0: 0\n",
      "Epoch  220 | loss 0.3133 | val R² 0.6639 | outputs with R²<0: 0\n",
      "Epoch  230 | loss 0.3126 | val R² 0.6646 | outputs with R²<0: 0\n",
      "Epoch  240 | loss 0.3121 | val R² 0.6660 | outputs with R²<0: 0\n",
      "Epoch  250 | loss 0.3112 | val R² 0.6654 | outputs with R²<0: 0\n",
      "Epoch  260 | loss 0.3128 | val R² 0.6680 | outputs with R²<0: 0\n",
      "Epoch  270 | loss 0.3104 | val R² 0.6684 | outputs with R²<0: 0\n",
      "Epoch  280 | loss 0.3093 | val R² 0.6697 | outputs with R²<0: 0\n",
      "Epoch  290 | loss 0.3120 | val R² 0.6698 | outputs with R²<0: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS     = 300\n",
    "BATCH_SIZE = 1024\n",
    "PATIENCE   = 30  \n",
    "\n",
    "N_train = X_train.shape[0]\n",
    "\n",
    "\n",
    "best_r2         = -float('inf')\n",
    "best_state      = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    #shuffle\n",
    "    perm = torch.randperm(N_train, device=device)\n",
    "    X_tr_shuf = X_train[perm]\n",
    "    y_tr_shuf = y_train[perm]\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches  = 0\n",
    "\n",
    "    for start in range(0, N_train, BATCH_SIZE):\n",
    "        end     = start + BATCH_SIZE\n",
    "        X_batch = X_tr_shuf[start:end]   # shape (1024, 6)\n",
    "        y_batch = y_tr_shuf[start:end]   # shape (1024, 113)\n",
    "\n",
    "        optimizer.zero_grad()          \n",
    "        pred = model(X_batch)           \n",
    "        loss = ((pred - y_batch) ** 2).mean()   \n",
    "        loss.backward()                 \n",
    "\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()                 # update weights\n",
    "        total_loss += loss.item()\n",
    "        n_batches  += 1\n",
    "\n",
    "    scheduler.step(epoch)   # update learning rate\n",
    "\n",
    "   \n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        val_pred = model(X_test)     \n",
    "        mean_r2, per_r2 = r2_score(y_test, val_pred)\n",
    "\n",
    "\n",
    "    if mean_r2 > best_r2 + 1e-5:\n",
    "        best_r2    = mean_r2\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        neg_outputs = (per_r2 < 0).sum().item()\n",
    "        print(f\"Epoch {epoch:4d} | loss {total_loss/n_batches:.4f} | \"\n",
    "              f\"val R² {mean_r2:.4f} | outputs with R²<0: {neg_outputs}\")\n",
    "\n",
    "\n",
    "model.load_state_dict({k: v.to(device) for k, v in best_state.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final mean R²:           0.6708\n",
      "Median R² across outputs: 0.6708\n",
      "Worst output R²:          0.5828\n",
      "Best  output R²:          0.8207\n",
      "Outputs with R² > 0.5:    113/113\n",
      "Outputs with R² < 0:      0/113\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_pred = model(X_test)\n",
    "    mean_r2, per_r2 = r2_score(y_test, final_pred)\n",
    "\n",
    "per_r2_np = per_r2.cpu().numpy()\n",
    "\n",
    "print(f\"\\nFinal mean R²:           {mean_r2:.4f}\")\n",
    "print(f\"Median R² across outputs: {per_r2_np.mean():.4f}\")  \n",
    "print(f\"Worst output R²:          {per_r2_np.min():.4f}\")\n",
    "print(f\"Best  output R²:          {per_r2_np.max():.4f}\")\n",
    "print(f\"Outputs with R² > 0.5:    {(per_r2_np > 0.5).sum()}/{len(per_r2_np)}\")\n",
    "print(f\"Outputs with R² < 0:      {(per_r2_np < 0.0).sum()}/{len(per_r2_np)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
